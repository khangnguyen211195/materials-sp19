{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\" style=\"border-style: hidden\" class=\"table\"> <tr><td class=\"col-md-2\"><img style=\"float\" src=\"http://prob140.org/assets/icon256.png\" alt=\"Prob140 Logo\" style=\"width: 120px;\"/></td><td><div align=\"left\"><h3 style=\"margin-top: 0;\">Probability for Data Science</h3><h4 style=\"margin-top: 20px;\">UC Berkeley, Fall 2018</h4><p>Ani Adhikari and Jim Pitman</p>CC BY-NC 4.0</div></td></tr></table><!-- not in pdf -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "# SETUP\n",
    "\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "from prob140 import *\n",
    "\n",
    "# These lines do some fancy plotting magic\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# These lines make warnings look nicer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "\n",
    "# Useful for probability calculations\n",
    "from scipy import stats\n",
    "from scipy import misc\n",
    "\n",
    "# Imports for interactive widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Lab Resources\n",
    "\n",
    "* [`prob 140` Library Documentation](http://prob140.org/prob140/)\n",
    "* [`datascience` Library Documentation](http://data8.org/datascience/)\n",
    "* [Prob 140 Code Reference Sheet](http://prob140.org/assets/prob140_code_reference.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "# Lab 3: Total Variation #\n",
    "Poisson distributions are often used as approximations to distributions of counts of rare events. In particular, the $Poisson(1)$ distribution approximates the distributions of some random counts that have $1$ as their most likely value.\n",
    "\n",
    "In class we studied two situations in which probabilities approach those in a Poisson distribution. One was binomial probabilities for large $n$ and small $p$, and the other was the probability of a specified number of matches in the matching problem.\n",
    "\n",
    "To quantify how good such approximations are, we need a measure of the distance between two probability distributions. In this lab you will develop the most commonly used distance. You used it in Data 8, but in this lab you will interpret it in terms of probabilities.\n",
    "\n",
    "In this lab we will look at the entire $Binomial (n, 1/n)$ distribution as well as the exact distribution of the number of matches, and compare them with their $Poisson (1)$ approximations. We will make the comparisons visually and also by a numerical measure of the distance between two distributions. In doing so we will find an upper bound for the amount of error in probability calculations when we approximate one distribution by another.\n",
    "\n",
    "What you will learn:\n",
    "- The definition of total variation distance (TVD) and its interpretation in terms of the amount of error in approximating probabilities\n",
    "- Properties of the TVD between the $Binomial (n, 1/n)$ and $Poisson (1)$ distributions as $n$ gets large\n",
    "- The computation of the exact distribution of the number of fixed points (matches) of a random permutation\n",
    "- Properties of the TVD between the distribution of the number of matches and the $Poisson (1)$ distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Part 1: Total Variation Distance ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Suppose you have two probability distributions on the same set of possible values $x_1, x_2, \\ldots , x_n$. Let the two distributions be $b_1, b_2, \\ldots, b_n$ and $g_1, g_2, \\ldots, g_n$, where for each $i$ the $b$-distribution assigns probability $b_i$ to the value $x_i$ and the $g$-distribution assigns probability $g_i$.\n",
    "\n",
    "The *total variation distance* between the two distributions is defined by\n",
    "\n",
    "$$\n",
    "tvd(b, g) = \n",
    "\\frac{1}{2} \\sum_{i=1}^n |b_i - g_i| \n",
    "$$\n",
    "\n",
    "The choice of notation comes from the blue and gold colors you will see in overlaid histograms below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 1a) Visualization ###\n",
    "Run the cell to display a histogram of the $Binomial (10, 1/10)$ distribution. Notice how the probabilities are concentrated on the low values. This is a signal to start thinking about Poisson approximations, even though the number of trials ($n = 10$) isn't very large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "n = 10                                    # number of trials\n",
    "\n",
    "k = range(n+1)                            # possible values\n",
    "binom_probs = stats.binom.pmf(k, n, 1/n)  # probabilities\n",
    "\n",
    "# Create a distribution object\n",
    "binom_dist = Table().values(k).probability(binom_probs)\n",
    "\n",
    "# Visualize\n",
    "Plot(binom_dist)\n",
    "plt.title('Binomial (10, 1/10) Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Roughly stated, a theorem we proved in class says that if $n$ is large and $p$ is small, then the $Binomial (n, p)$ probabilities look like $Poisson (np)$ probabilities. Even though $10$ isn't very large, compare the $Binomial (10, 1/10)$ and $Poisson (1)$ distributions. Run the cell below to display the $Poisson (1)$ histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "poisson_1_probs = stats.poisson.pmf(k, 1)\n",
    "poisson_1_dist = Table().values(k).probability(poisson_1_probs)\n",
    "Plot(poisson_1_dist)\n",
    "plt.title('Poisson (1) Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "This is the fundamental distribution of this lab, so take a good look at it. Notice the two modes, at $0$ and $1$. Notice also that even though the possible values are the infinite set of all the non-negative integers, virtually all the probability is concentrated in the $0$ through $5$ range.\n",
    "\n",
    "The $Binomial (10, 1/10)$ and $Poisson (1)$ distributions do resemble each other, but not very closely. Run the cell below to draw overlaid histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "Plots('Binomial (10, 1/10)', binom_dist, 'Poisson (1)', poisson_1_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "The total variation distance between the two distributions is the total amount by which the areas of the blue bars exceed those of the corresponding gold bars. That's exactly equal to the total amount by which the gold bars exceed the blue.\n",
    "\n",
    "This is almost apparent from the definition of total variation distance, and you will prove it in homework. Just assume it for now as you did in Data 8. It is an intuitively reasonable measure of the difference between two distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 1b) Computing TVD ###\n",
    "Define a function `tvd` that takes two arrays and returns the total variation distance between them. It's fine to assume that both of the input arrays are probability distributions; you don't have to include code to check that each array is non-negative and sums to $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tvd(b, g):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "When the two arrays are $b = [0.4, 0.3, 0.2, 0.1]$ and $g = [0.25, 0.25, 0.25, 0.25]$, the histograms look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "b = make_array(0.4, 0.3, 0.2, 0.1)\n",
    "g = make_array(0.25, 0.25, 0.25, 0.25)\n",
    "k = np.arange(4)\n",
    "blue_dist = Table().values(k).probability(b)\n",
    "gold_dist = Table().values(k).probability(g)\n",
    "Plots('Non-uniform', blue_dist, 'Uniform', gold_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Calculate the TVD mentally. Then run the cell below to confirm that your function `tvd` is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "tvd(make_array(0.4, 0.3, 0.2, 0.1), make_array(0.25, 0.25, 0.25, 0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 1c) Another Way of Interpreting TVD (on whiteboard, don't submit) ###\n",
    "Thus far, our interpretation of total variation distance has been essentially geometric: the amount by which the blue bars exceed the gold. There is an equivalent interpretation in terms of probabilities that makes it easier to understand what the numerical value of the distance is telling us.\n",
    "\n",
    "Suppose you have a finite set of possible values, and a choice of two probability distributions to use for finding probabilities. For example, the choices might be the exact distribution of a random variable and an approximate distribution. \n",
    "\n",
    "**The total variation distance between the two distributions is the biggest difference you can possibly get if you compute the probability of an event using each of the two distributions.**\n",
    "\n",
    "Formally, if $S$ is the space of all possible values, then the total variation distance between the blue and gold distributions is equal to\n",
    "\n",
    "$$\n",
    "\\max\\{ \\big{\\lvert} P_{blue}(A) - P_{gold}(A) \\big{\\rvert} : A \\subseteq S\\}\n",
    "$$\n",
    "\n",
    "This can be shown in a few straightforward steps and you will do that in homework. For now, confirm that it is true for the distributions in **1b**, in the following steps.\n",
    "\n",
    "- Figure out how many events can be created out of the outcomes $\\{0, 1, 2, 3\\}$.\n",
    "- List all the events.\n",
    "- For each event, compute the absolute difference between the blue and gold probabilities of the event. Your goal is to find the biggest possible absolute difference, so you might not even need to compute each one.\n",
    "- See which event or events correspond to the biggest absolute difference, and compare the value of that absolute difference with the TVD that you computed in **1b**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 1d) Poisson Approximation ###\n",
    "Suppose you want to approximate the $Binomial (1000, 0.0025)$ distribution by a Poisson distribution. Which Poisson distribution will you use? Create two numpy arrays (using functions from the `stats` package) representing the $Binomial (1000, 0.0025)$ distribution and your chosen Poisson distribution. Once you have decided that, use your function `tvd` to compute the total variation distance between the two distributions. \n",
    "\n",
    "**Note:** Don't worry that the Poisson distribution has an infinite set of possible values and the values of the Binomial distribution only go up to $1000$. Just restrict the Poisson to go up to $1000$ and no further. You know that when $p$ is small, the $Binomial (n, p)$ distribution and its Poisson approximation only have a few bars with any significant probability, and they're all at the low end of the possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binom_probs = ...\n",
    "poisson_probs = ...\n",
    "tvd(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### Interpretation ###\n",
    "If $X$ has the $Binomial (1000, 0.0025)$ distribution, and for some set $A$ you find $P(X \\in A)$ using the Poisson approximation instead of the exact binomial distribution, then your approximation will be off by at most the TVD you have calculated.\n",
    "\n",
    "Small TVD, small error. You knew that intuitively already, but now you can quantify it more sharply.\n",
    "\n",
    "See what happens if you approximate the same $Binomial (1000, 0.0025)$ probabilities by a different Poisson distribution than the one you chose. Run the cell below and drag the slider to the value of the Poisson parameter you chose above. Then, drag the slider to a slightly different parameter. See what happens to the TVD and hence to the amount of error in approximating probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "interact(lambda mu: print('tvd:', tvd(stats.binom.pmf(range(1001), 1000, 0.0025),\n",
    "                                      stats.poisson.pmf(range(1001), mu))), \n",
    "         mu=widgets.FloatSlider(min=2., max=3., step=0.01, value=2.));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "#newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Part 2: The $Binomial (n, 1/n)$ Distribution ##\n",
    "We proved in lecture that if $n \\to \\infty$ and $p_n \\to 0$ so that $np_n \\to \\mu > 0$, then for each $k$ the $Binomial (n, p_n)$ probability of $k$ converges to the $Poisson (\\mu)$ probability of $k$.\n",
    "\n",
    "Let $p_n = 1/n$ in the statement above. Then for each $k$, the $Binomial (n, 1/n)$ probability of $k$ converges to the $Poisson (1)$ probability of $k$. \n",
    "\n",
    "In Part 1 of the lab you compared the $Binomial (10, 1/10)$ distribution and the $Poisson (1)$ distribution. We will now extend that by comparing the $Binomial (n, 1/n)$ distribution and the $Poisson (1)$ distribution using total variation distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 2a) TVD between $Binomial (n, 1/n)$ and $Poisson (1)$ ###\n",
    "Define a function `binomial_poisson_tvd` that takes $n$ as its argument and returns the total variation distance between the $Binomial (n, 1/n)$ and $Poisson (1)$ distributions. As before, it's fine to compute the $Poisson (1)$ probabilities only on 0 through $n$, the possible values of the binomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binomial_poisson_tvd(n):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "As a check to see if your function is working correctly, run the cell below. The output should be about $1$%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "binomial_poisson_tvd(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 2b) Visualization ###\n",
    "Extend `tvd_table` below with a column labeled `'Binomial (n, 1/n)'` that contains the TVD between the $Binomial (n, 1/n)$ and $Poisson (1)$ distributions, where in each row $n$ is given by the entry in Column 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tvd_table = Table().with_column('n', np.arange(5, 101))\n",
    "\n",
    "tvds = tvd_table...\n",
    "\n",
    "tvd_table = tvd_table...\n",
    "\n",
    "tvd_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Now draw a graph of the TVD as a function of $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "...\n",
    "plt.title('TVD between Binomial (n, 1/n) and Poisson (1)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Notice how sharply the function drops. Fill in the blanks (the code cell below might help):\n",
    "\n",
    "For $n$ values about $\\underline{~~~~~~~~~~~~~~~~}$ or more, $Poisson (1)$ approximations to $Binomial (n, 1/n)$ probabilities will be off by at most 0.5%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "You can use total variation distance to help answer the question, \"How large does $n$ have to be before I can use the $Poisson (1)$ approximation to the $Binomial (n, 1/n)$ distribution?\" \n",
    "\n",
    "- First decide how much error you are prepared to tolerate in your approximations. \n",
    "- Then use `tvd_table` (or an extended one with larger values of $n$) to find the smallest $n$ for which the TVD is below your threshold error. \n",
    "- For that $n$ or larger, the error in your $Poisson (1)$ probability approximations will be below your threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "#newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Part 3: Fixed Points of a Random Permutation ##\n",
    "\n",
    "Let $M_n$ be the number of fixed points in a random permutation of the values $1, 2, 3, \\ldots, n$. You can think of $M_n$ as the number of matches when $n$ letters labeled $1$ through $n$ are permuted randomly into $n$ envelopes labeled $1$ through $n$.\n",
    "\n",
    "[Recall](http://prob140.org/textbook/chapters/Chapter_05/03_The_Matching_Problem) that the distribution of $M$ is given by \n",
    "$$\n",
    "P(M_n = k) ~ = ~ \n",
    "\\frac{1}{k!} \\cdot \\big{(} 1 - \\frac{1}{1!} + \\frac{1}{2!} - \\frac{1}{3!} + \\cdots (-1)^{n-k}\\frac{1}{(n-k)!} \\big{)} \\\\\n",
    "$$\n",
    "for $0 \\le k \\le n$.\n",
    "\n",
    "Also, if $n$ is large, recall that for each fixed $k$ we have the approximation \n",
    "$$\n",
    "P(M_n = k) ~ \\approx ~ \\frac{e^{-1}}{k!}\n",
    "$$ \n",
    "\n",
    "These are the terms in the $Poisson(1)$ distribution.\n",
    "\n",
    "In this part of the lab you will compare the distribution of $M_n$ with its $Poisson(1)$ approximation, both visually and by studying the total variation distance between the two distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 3a) Computing $P(M_n = k)$ ###\n",
    "Complete the function `prob_matches` defined below which takes $k$ and $n$ as its arguments and returns $P(M_n = k)$.\n",
    "\n",
    "Use array operations. It is helpful that `misc.factorial(integer_array)` gives you an array consisting of the factorials of all the integers in `integer_array`. The module `misc` has already been imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_matches(k, n):\n",
    "    x_even = np.arange(0, n - k + 1, 2)\n",
    "    x_odd = np.arange(1, n - k + 1, 2)\n",
    "    \n",
    "    \n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "To confirm that your function is working correctly, think about what $P(M_n = n-1)$ should be, and then run the cell below to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "prob_matches(99, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "For further confirmation, run the cell below to compare the output of the function to its $Poisson (1)$ approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "prob_matches(5, 100), stats.poisson.pmf(5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Once you are confident your function works, run the following cell. As the Poisson approximation would predict, the two values should be close. Explain why the exact values are almost the same. (Hint: Think about how much they should differ by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "prob_matches(0, 100), prob_matches(1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Run the cell below and explain what you see using the Poisson approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_matches(5, 100), prob_matches(5, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 3b) The Distribution of $M_n$ ###\n",
    "Use `prob_matches` to define a function `match_dist` that takes $n$ as its argument and returns an array consisting of the probabilities $P(M_n = k)$ for $0 \\le k \\le n$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "The expression `match_dist(100)[0:11]` evaluates to an array consisting of the elements $0$ through $10$ of `match_dist(100)`. Explain what the output of the cell below tells you about the distribution of $M_n$. As with most questions about random variables, start by thinking about the possible values of $M_n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(match_dist(100)[0:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "What does the histogram below display? Which histogram in Part 1 does it resemble?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "k = np.arange(11)\n",
    "match_100 = match_dist(100)[0:11]\n",
    "match_100_dist = Table().values(k).probability(match_100)\n",
    "Plot(match_100_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 3c) Total Variation Distance ###\n",
    "Use the `stats` module and functions you have already defined in this lab to define a new function `matches_poisson_tvd` that takes $n$ as its argument and returns the total variation distance between the distribution of $M_n$ and the $Poisson (1)$ distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matches_poisson_tvd(n):\n",
    "    \n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Extend `tvd_tables` defined in **2b** with a column labeled `'Matches (n)'` that contains the total variation distance between the exact distribution of the number of matches and its $Poisson (1)$ approximation. As before, in each row, $n$ is given by the entry in Column 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tvds = tvd_table...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Plot the two TVDs (Binomial/Poisson and matching/Poisson) as functions of $n$ on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "To see why the new plot falls so steeply, look back at the formula for $P(M_n = k)$ given at the beginning of this part of the lab. It's essentially the same as the $Poisson (1)$ probability function, except that the infinite sum of $e^{-1}$ has been replaced by a partial sum. For large $n$ and small $k$, there's not much difference between the two. For large $k$ the chance is close to $0$ anyway.\n",
    "\n",
    "Look at the table below for numerical confirmation of the steep drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "tvd_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "If $n \\ge 10$ you might as well use the $Poisson (1)$ distribution for the number of matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Conclusion ##\n",
    "What you have learned in this lab:\n",
    "- If you use an approximation to the distribution of $X$, then the total variation distance between the exact and approximate distributions measures the worst error you can make in approximating probabilities of events determined by $X$. You didn't prove that in the lab but you will for homeowrk.\n",
    "- The total variation distance between the $Binomial (n, 1/n)$ and $Poisson (1)$ distributions falls sharply as a function of $n$ and is below $1$% even for moderate values of $n$.\n",
    "- The total variation distance between the distribution of the number of matches in a random permutation of $n$ elements and its $Poisson (1)$ approximation falls even more sharply. By about $10$ elements or so, you might as well use the Poisson distribution for the number of matches.\n",
    "- The random variables in this lab all have possible values $0$ through $n$. That's a large number of possible values when $n$ is large, and the approximating Poisson distribution has infinitely many possible values. But no matter how large $n$ is, the *probable* values are in a very small range – $0$ through about $8$ or $10$ – because all of the distributions are roughly $Poisson (1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false,
    "collapsed": true
   },
   "source": [
    "## Submission Instructions\n",
    "\n",
    "1. **Save your notebook using File > Save and Checkpoint.**\n",
    "2. Run the cell below to generate a pdf file.\n",
    "3. Download the pdf file and confirm that none of your work is missing or cut off.\n",
    "4. Submit the assignment to Lab03b on Gradescope.\n",
    "\n",
    "#### Logistics \n",
    "\n",
    "1. Examine the generated pdf before uploading to make sure that it contains all of your work.\n",
    "2. When submitting to Gradescope, select the pages of your upload corresponding to each question. \n",
    "3. If you encounter any difficulties when submitting or exporting your assignment, please make a private Piazza post **before the deadline**. \n",
    "\n",
    "### **We will not grade assignments which do not have pages selected for each question or were submitted after the deadline.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gsExport\n",
    "gsExport.generateSubmission(\"Lab03.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "checksums": [
   "41e5cd3e7433650be1eb792ff2fd6228",
   "1bd05bcd2ff4c54d73a87b081f67bfe8",
   "bbbd0bf658428e10cbfd889247879924",
   "ca8513626c5107737f4063cd28999aec",
   "215ed6c8654224bcdb429ca58d5e7135",
   "4fb206b23cca8f1941265599b0f0f320",
   "fd7968aa69f28c7da1e3f2bbbf432ea5",
   "f574a28ce01e40f21192c10030534412",
   "27666ff3fa9a0560f30908517688ad46",
   "2568afdaf57c4b446585d2b5dcf3faa8",
   "6fa0f4e8973db77dfe16c584b7ca0c6c",
   "b15d8069cc8fc1268435a1c27c718aa5",
   "acdc27304328980a2494541f363204af",
   "4dd3ede142b2dedbd74013e7f6686124",
   "b182444b425e530aebac0b1429b8d999",
   "dd794f506fbb1e55483d6ba8c620c167",
   "5d641c73fa604f84c3d41d23750ed1da",
   "c0125a6ddcffa9a6525c1d3f5d9715ca",
   "a322812c7a1b35c946339539896f0897",
   "cd4107610f923b93951d9ecad8aef60c",
   "a7820a1f1154ccea940db68c2b31bdbd",
   "6f329217f09b840d18cce1da49064b89",
   "01cd52a0f8c7d685d29109b8ebc566fc",
   "4c9e3bf0ffddb3f56d60f27cf4552f45",
   "640061103a186fd26f59746dd4d6de57",
   "6d0672829f2806824b2ec717001ab638",
   "275a4399dcd28a3829f93bbe096d6f64",
   "6c7a9f86b1f43bcbfc8fffe49634afff",
   "732477c7f5d4080670738ff6df6da214",
   "e3d21feaca36597a71831c656315cad5",
   "9ee02aadeb20d4a7ab416f5a8ab63cac",
   "abe7e728ba3b9ea9453ff260d012b675",
   "6fd1945cb3e3eb19600f80b574922e49",
   "6ffc1f0498e2ef6453f3176c7c457fab",
   "8c8e6e34566f95cd92441c625651902b",
   "0de20b93bb878d597e59213991465648",
   "ac946bca5429e38e748190192492b7de",
   "640061103a186fd26f59746dd4d6de57",
   "853181bf3d0160257526b01adb4bc9de",
   "1e0e3fe4c4edfb9b620c43979d851bac",
   "6c38060921d0644aa07c96678cb142d8",
   "61eabfbb6c12528de4cb52a76fa50a81",
   "1c9082e82d8238d32d369f3533ca5e8c",
   "dae71e2f15ba14bf553d0fc3a5323cc2",
   "6d7fe73ebc69045e959388c448593aab",
   "c6e707422be76d3674d27edf00e9ec99",
   "b9b9cba3588e3769333618b5f4f304d6",
   "0de20b93bb878d597e59213991465648",
   "7f361197ab89dbfd2c8922a52318b4ac",
   "3ad40e342bc342c928f112dd0fec6fc6",
   "0de20b93bb878d597e59213991465648",
   "04476631f67afa31b5fafe5aff09193c",
   "2f43b42fd833d1e77420a8dae7419000",
   "5a326898c082718910c14e2f6e3d2e0e",
   "25df0da9d04ff98129e0a93242a87af4",
   "3a76d7cce4e9ecdb4fe70737e7879960",
   "c8883e612bc690fd2539441bef8fd115",
   "38f4d0ae6029753b7c70d9a33eb4cced",
   "3a76d7cce4e9ecdb4fe70737e7879960",
   "5fb175cd519f1f4901d3abda7237271b",
   "84345fe8b33728de27e76a86fff66b15",
   "5e5f99f88094e7a039a81ea97d932d56",
   "5203c782a716c29c5ad8070981fc5b74",
   "49ce2505519e9db161ac76d6853132ae",
   "2f43b42fd833d1e77420a8dae7419000",
   "64be920ff777ddd6281801884ae0d027",
   "d541ec8dec887a76a818d1623be5bb36",
   "10bb35623f1010a9077d83b77db4023d",
   "ba0966264845a461a8656dfe655c4001",
   "f3db9766684f2a8682cb15d722692657",
   "e2992e40a9395392c6e4a37b8bcc99a1"
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "number_of_pagebreaks": 2,
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
